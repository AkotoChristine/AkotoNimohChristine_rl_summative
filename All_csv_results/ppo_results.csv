Full Name,Configuration,Mean Reward,Std Reward,Learning Rate,Batch Size,N Steps,Gamma,Entropy Coef,model_exists,raw
PPO_HighEntropy,PPO_HighEntropy,262.9650937786918,276.62876515813076,0.0003,64,2048,0.99,0.01,True,"{'name': 'PPO_HighEntropy', 'config': {'name': 'PPO_HighEntropy', 'learning_rate': 0.0003, 'n_steps': 2048, 'batch_size': 64, 'n_epochs': 10, 'gamma': 0.99, 'gae_lambda': 0.95, 'clip_range': 0.2, 'ent_coef': 0.01, 'vf_coef': 0.5, 'max_grad_norm': 0.5}, 'mean_reward': 262.9650937786918, 'std_reward': 276.62876515813076, 'model': <stable_baselines3.ppo.ppo.PPO object at 0x7cd4c449ca90>}"
PPO_LowLR,PPO_LowLR,257.27951253574247,234.41801840454224,0.0001,64,2048,0.99,0.0,True,"{'name': 'PPO_LowLR', 'config': {'name': 'PPO_LowLR', 'learning_rate': 0.0001, 'n_steps': 2048, 'batch_size': 64, 'n_epochs': 10, 'gamma': 0.99, 'gae_lambda': 0.95, 'clip_range': 0.2, 'ent_coef': 0.0, 'vf_coef': 0.5, 'max_grad_norm': 0.5}, 'mean_reward': 257.27951253574247, 'std_reward': 234.41801840454224, 'model': <stable_baselines3.ppo.ppo.PPO object at 0x7cd4c43bef50>}"
PPO_Baseline,PPO_Baseline,218.60576739467265,138.56804241433164,0.0003,64,2048,0.99,0.0,True,"{'name': 'PPO_Baseline', 'config': {'name': 'PPO_Baseline', 'learning_rate': 0.0003, 'n_steps': 2048, 'batch_size': 64, 'n_epochs': 10, 'gamma': 0.99, 'gae_lambda': 0.95, 'clip_range': 0.2, 'ent_coef': 0.0, 'vf_coef': 0.5, 'max_grad_norm': 0.5}, 'mean_reward': 218.60576739467265, 'std_reward': 138.56804241433164, 'model': <stable_baselines3.ppo.ppo.PPO object at 0x7cd4c43be7d0>}"
PPO_LargeBatch,PPO_LargeBatch,187.34862925154567,232.60482397445014,0.0003,256,2048,0.99,0.0,True,"{'name': 'PPO_LargeBatch', 'config': {'name': 'PPO_LargeBatch', 'learning_rate': 0.0003, 'n_steps': 2048, 'batch_size': 256, 'n_epochs': 10, 'gamma': 0.99, 'gae_lambda': 0.95, 'clip_range': 0.2, 'ent_coef': 0.0, 'vf_coef': 0.5, 'max_grad_norm': 0.5}, 'mean_reward': 187.34862925154567, 'std_reward': 232.60482397445014, 'model': <stable_baselines3.ppo.ppo.PPO object at 0x7cd4c0552550>}"
PPO_MoreEpochs,PPO_MoreEpochs,172.97942930105518,313.08703516912954,0.0003,64,2048,0.99,0.0,True,"{'name': 'PPO_MoreEpochs', 'config': {'name': 'PPO_MoreEpochs', 'learning_rate': 0.0003, 'n_steps': 2048, 'batch_size': 64, 'n_epochs': 20, 'gamma': 0.99, 'gae_lambda': 0.95, 'clip_range': 0.2, 'ent_coef': 0.0, 'vf_coef': 0.5, 'max_grad_norm': 0.5}, 'mean_reward': 172.97942930105518, 'std_reward': 313.08703516912954, 'model': <stable_baselines3.ppo.ppo.PPO object at 0x7cd4c436f290>}"
PPO_SmallBatch,PPO_SmallBatch,167.66223284957087,373.80868120059586,0.0003,32,2048,0.99,0.0,True,"{'name': 'PPO_SmallBatch', 'config': {'name': 'PPO_SmallBatch', 'learning_rate': 0.0003, 'n_steps': 2048, 'batch_size': 32, 'n_epochs': 10, 'gamma': 0.99, 'gae_lambda': 0.95, 'clip_range': 0.2, 'ent_coef': 0.0, 'vf_coef': 0.5, 'max_grad_norm': 0.5}, 'mean_reward': 167.66223284957087, 'std_reward': 373.80868120059586, 'model': <stable_baselines3.ppo.ppo.PPO object at 0x7cd4c0551790>}"
PPO_HighLR,PPO_HighLR,100.06132973082849,237.30586966091,0.001,64,2048,0.99,0.0,True,"{'name': 'PPO_HighLR', 'config': {'name': 'PPO_HighLR', 'learning_rate': 0.001, 'n_steps': 2048, 'batch_size': 64, 'n_epochs': 10, 'gamma': 0.99, 'gae_lambda': 0.95, 'clip_range': 0.2, 'ent_coef': 0.0, 'vf_coef': 0.5, 'max_grad_norm': 0.5}, 'mean_reward': 100.06132973082849, 'std_reward': 237.30586966091, 'model': <stable_baselines3.ppo.ppo.PPO object at 0x7cd4c441ad50>}"
PPO_LargeClip,PPO_LargeClip,96.94574519314332,353.811849411941,0.0003,64,2048,0.99,0.0,True,"{'name': 'PPO_LargeClip', 'config': {'name': 'PPO_LargeClip', 'learning_rate': 0.0003, 'n_steps': 2048, 'batch_size': 64, 'n_epochs': 10, 'gamma': 0.99, 'gae_lambda': 0.95, 'clip_range': 0.3, 'ent_coef': 0.0, 'vf_coef': 0.5, 'max_grad_norm': 0.5}, 'mean_reward': 96.94574519314332, 'std_reward': 353.811849411941, 'model': <stable_baselines3.ppo.ppo.PPO object at 0x7cd4c43be810>}"
PPO_SmallClip,PPO_SmallClip,84.9610451953169,307.88291670505697,0.0003,64,2048,0.99,0.0,True,"{'name': 'PPO_SmallClip', 'config': {'name': 'PPO_SmallClip', 'learning_rate': 0.0003, 'n_steps': 2048, 'batch_size': 64, 'n_epochs': 10, 'gamma': 0.99, 'gae_lambda': 0.95, 'clip_range': 0.1, 'ent_coef': 0.0, 'vf_coef': 0.5, 'max_grad_norm': 0.5}, 'mean_reward': 84.9610451953169, 'std_reward': 307.88291670505697, 'model': <stable_baselines3.ppo.ppo.PPO object at 0x7cd4c04f0b10>}"
PPO_FewerEpochs,PPO_FewerEpochs,82.5998677162645,193.04717886300028,0.0003,64,2048,0.99,0.0,True,"{'name': 'PPO_FewerEpochs', 'config': {'name': 'PPO_FewerEpochs', 'learning_rate': 0.0003, 'n_steps': 2048, 'batch_size': 64, 'n_epochs': 5, 'gamma': 0.99, 'gae_lambda': 0.95, 'clip_range': 0.2, 'ent_coef': 0.0, 'vf_coef': 0.5, 'max_grad_norm': 0.5}, 'mean_reward': 82.5998677162645, 'std_reward': 193.04717886300028, 'model': <stable_baselines3.ppo.ppo.PPO object at 0x7cd4d0d1f310>}"
